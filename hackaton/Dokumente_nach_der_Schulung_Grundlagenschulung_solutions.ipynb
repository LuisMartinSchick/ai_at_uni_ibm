{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgfvOyuQ6pTi"
   },
   "source": [
    "# Linkit Grundlagenschulung (1. Teil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjVVod5nsY_g"
   },
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVqL3tK1tPsa"
   },
   "source": [
    "An established food retailer has introduced a self-scanning system that allows customers to scan their items using a handheld mobile scanner while shopping. This type of payment leaves retailers open to the risk that a certain number of customers will take advantage of this freedom to commit fraud by not scanning all of the items in their cart.\n",
    "\n",
    "To minimize losses, the food retailer hopes to identify cases of fraud using targeted follow-up checks. The challenge here is to keep the number of checks as low as possible to avoid unnecessary added expense as well as to avoid putting off innocent customers due to false accusations. The objective is to create a model to classify the scans as fraudulent or non-fraudulent. The classification does not take into account whether the fraud was committed intentionally or inadvertently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ng06tLSOsdIx"
   },
   "source": [
    "- **Trust Level** ~ A customers trust level rated between 1-6\n",
    "- **Total scan time in sec** ~ total time in seconds between first and last product scanned\n",
    "- **Grand total** ~ Total of products scanned\n",
    "- **Scans without registration** ~ Attempts to scan something without actually scanning something\n",
    "- **Scanned lined items per seconds** ~ Average number of scanned products\n",
    "- **Value per second** ~ Average total value per second\n",
    "- **Line items void per Position** ~ Avg number of item voids per total nr of all scanned and not canceled product\n",
    "- **Customer Sex** ~ Information about the sex of the customer\n",
    "- **Store Location** ~ Location of the Store\n",
    "- **Payment Type** ~ Information on the type of payment (credit card, debit card, ...) used for  the transaction\n",
    "- **Fraud** ~ Fraudulent (1) or not fraudulent (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax7c5bjPUBqv"
   },
   "source": [
    "## 2. Data Understanding: Quick Overview\n",
    "How do we get a quick overview over the data set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6SRnWRRXia5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-FVTlzkW401"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soC7CHtWQlHZ"
   },
   "source": [
    "After successfull data import its essential to have a look at the data to check whether the import was successfull and to get an overall impression on data types, number of Null-counts etc.\n",
    "\n",
    "The pandas library provides several methods for that, lets have a look at it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*df.head()* shows the first n rows (default: 5) of the dataframe. It is commonly used to quickly test whether the data input was successfull and to get a solid overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "s_zm0GF7T3e7",
    "outputId": "dd899fda-bfae-42ec-dd4d-9d632e247801"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "Inx5awBEFSXL",
    "outputId": "bd8f9945-a41a-4064-d624-ade7c35bfbf3"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*df.info()* shows information about the dataframe including datatypes of each feature. This is super useful to detect whether there are for example any NaN values or if the columns appear in their expected data type, such as float32 or 64, int32 or 64, String, boolean,...). For example, if in a later stage some calculations fail, it is often worth a look to check whether the data types are of their expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KiNE4cd5Y1A_",
    "outputId": "21494e87-9137-42a2-ab15-ec2f0b131468"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*df.describe()* shows some descriptive statistics about the data. It gives a comprehensive understanding on the distribution per column and shows for example min and max values.\n",
    "\n",
    "For us, it is useful to really get a good understanding of our features so that in a later step we are able to decide which one to use for modeling tasks. Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "0t4zsXXiFUP7",
    "outputId": "e7297699-f354-4c01-f141-b27a90fbc272"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you: What is your first impression on the data? Any inconsistencies? Everything okay? Please take a look and share your thoughts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNBdc-X5RZU6"
   },
   "source": [
    "After gaining a first impression with the methods explained before, it might be crucial to look at some rows or columns in more detail. Moreover, these methods that will be explained here are helpul to select data by position or index and thus allows intuitive getting and setting of subsets.\n",
    "\n",
    "Data can be selected as follows:\n",
    "\n",
    "(1) by one or several column names,\n",
    "\n",
    "(2) using a conditional selection of column values,\n",
    "\n",
    "(3) by index position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a column, the columns name has to be handed over by using squared brackets []. Like this, a lower-dimensional slice of the data is selected <br/>\n",
    "(Hint: Strings, usually the data type of column headers, have to be handed over within ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYVuhmryVcLV",
    "outputId": "65c4a8d1-4ae4-405f-85f6-4b4b4a6107c1"
   },
   "outputs": [],
   "source": [
    "# selection by column\n",
    "# ...using single brackets will output a Pandas Series\n",
    "data['trustLevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...using double brackets will output a Pandas DataFrame\n",
    "data[['trustLevel']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, it is also possible to select multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "VZo4nEFyjJSa",
    "outputId": "b1b8717d-ac89-40d5-99ef-9fe61204f5b9"
   },
   "outputs": [],
   "source": [
    "# selection of several columns\n",
    "data[['scannedLineItemsPerSecond', 'valuePerSecond']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, it is possible to select only those entries of a column that fulfill a certain condition. As you have learned in the DataCamp course, a conditional query can be expressed using ==.\n",
    "For better understanding, lets see what happens if we add this conditional expression to our selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition\n",
    "data['fraud']==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite what we wanted to see... It gives an understanding of which rows fulfill the expression, but as before we want to obtain the origional data. To archieve this, the conditional selection needs to be integrated into the actual selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "hW7fuL1fOiWT",
    "outputId": "250cfeb1-b4a6-422a-8775-5e111d054c35"
   },
   "outputs": [],
   "source": [
    "# conditional selection\n",
    "data[data['fraud']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly used and important way of performing label-based selections is using the method *loc*. *Loc* is a method for accessing rows and columns by passing a label, a list of labels, or a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "HcrXfEe4Iovp",
    "outputId": "a5f84904-442e-4f4f-d823-ee3518238b46"
   },
   "outputs": [],
   "source": [
    "# another way to perform conditional selection / access by label\n",
    "data.loc[(data['trustLevel']==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 47
    },
    "id": "9HUZc9v4F7z7",
    "outputId": "18d0fcd1-b52f-46f1-d47c-32751b0687c7"
   },
   "outputs": [],
   "source": [
    "# conditional selection of one column\n",
    "data.loc[(data['trustLevel']==3), ['scansWithoutRegistration']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select values by their position, the method *iloc* is used. *Iloc* is integer position based so that either a single int or a range of ints have to be handed over to access the respective positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection by position\n",
    "data.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "-1R3BDfwF722",
    "outputId": "b26b1e38-dd68-4862-85b3-ba71c73e815d"
   },
   "outputs": [],
   "source": [
    "data.iloc[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the index position of a selection, the functions *Index.values* is used. *Index* stores all axis labels. With *values*, a numpy representation of the Index can be retreived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQ4_UiShvabI",
    "outputId": "6c1cf125-15f4-48f4-edbc-7da72632166c"
   },
   "outputs": [],
   "source": [
    "# get Index:\n",
    "list(data[data['storeLocation']=='München'].index.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LJudSB9TCPp"
   },
   "source": [
    "Often it is usefull to create a copy of the dataframe. This can be done by either create a deep copy which creates a new object with a copy of an objects inidces and data (deep=True). All modifications to the copied dataframe will not be reflected in the origional dataframe. Another possibility is to create a shallow copy (deep=False) with references to the origional datas inidces and data, so that any changes to the origional dataframe will be reflected in the copy as well. The pandas function .copy() creates a deep copy by default.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQJcM-9TSs1J"
   },
   "outputs": [],
   "source": [
    "# create a copy of the dataframe\n",
    "data_new = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnwEFdnvF75o"
   },
   "outputs": [],
   "source": [
    "# moreover sometimes it might be good to delete a column, e.g. when their information is not usefull for your task\n",
    "data_new = data_new.drop(columns='customer_sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "M2m3bU6BVzNP",
    "outputId": "47984a84-1ffc-4f47-f66d-9acd2f54b322"
   },
   "outputs": [],
   "source": [
    "data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Find comprehensive explanations and exploit further methods in the pandas documentation:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.values.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IOLSSbNXFfO"
   },
   "source": [
    "### Now you: Data Overview\n",
    "\n",
    "Perform the following selections:\n",
    "1.    Return all purchases where the number of scans without registration is higher than 5. \n",
    "2.    How many purchases with a trust level below 2 are done in Munich?\n",
    "3.    What is the maximum scanned line items per second of those purchases that include more than three scans without registration?\n",
    "4.    Return the index of the purchases where the grandTotal is higher than 60 and the trust level below 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)\n",
    "data.loc[(data['scansWithoutRegistration'] > 5)]\n",
    "# data[(data['scansWithoutRegistration'] > 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "data.loc[(data['trustLevel']<2) & (data['storeLocation'] == 'München')].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)\n",
    "# data['scannedLineItemsPerSecond'].loc[data['scansWithoutRegistration']> 3].max()\n",
    "data.loc[data['scansWithoutRegistration']> 3, ['scannedLineItemsPerSecond']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\n",
    "data2 = data.loc[(data['grandTotal'] > 60.0 ) & (data['trustLevel']<3)]\n",
    "list(data2.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDDuBcZnuPgM"
   },
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkE57DFtWJ8Q"
   },
   "source": [
    "Sometimes our dataset inlcudes one or multiple existing information (features) that can be thoughtfully combined to a new feature providing additional information. Let's have a look if we can find something in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "0d2WkPReDE24",
    "outputId": "fc590ac7-c3e6-4fbb-e1af-b3ebb4a05900"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atuc-j7YjJVC",
    "outputId": "97069f46-cdcb-424b-9e43-44586c544507"
   },
   "outputs": [],
   "source": [
    "# example for feature generation: use scanTimeInSeconds multiplied with scannedLineItemsPerSecond to get the total number of items scanned\n",
    "data['totalItems'] = (data['totalScanTimeInSeconds']*data['scannedLineItemsPerSecond'])\n",
    "data['totalItems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fks8TPz-0tr3"
   },
   "outputs": [],
   "source": [
    "data['checkoutTime'] = data['checkoutTime'].astype(np.datetime64)\n",
    "data['checkoutDate'] = data['checkoutTime'].dt.date\n",
    "data['checkoutDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU8OfxlWWOcc"
   },
   "source": [
    "### Now You: Feature Generation\n",
    "\n",
    "Calculate the following features and save them as a new column: \n",
    "\n",
    "1. Time features: \n",
    "    1. Checkout month\n",
    "    2. Checkout year\n",
    "    3. Hour of checkout\n",
    "    \n",
    "\n",
    "2. Price feature: Average Price per Item in a Transaction\n",
    "\n",
    "**Note**: Save the value as a new column called 'meanPricePerItem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joxVa48LjJW9"
   },
   "outputs": [],
   "source": [
    "# 1)\n",
    "data['checkoutMonth'] = data['checkoutTime'].dt.month\n",
    "data['checkoutYear'] = data['checkoutTime'].dt.year\n",
    "data['checkoutDayTime'] = data['checkoutTime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "data['meanPricePerItem'] = (data['grandTotal'] / data['totalItems'])\n",
    "data['meanPricePerItem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vT46qGbfrtpf"
   },
   "source": [
    "see more here: pandas doc https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_tk7XGzUlRo"
   },
   "source": [
    "## 3. Data Understanding: Data Visualization & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiqZ7lyN3neF"
   },
   "source": [
    "In order to gain insight into our data through plots, we can use several libraries.\n",
    "Some of them are briefly introduced below.\n",
    "The most important is the Python standard library called Matplotlib. Its a useful tool when we want to create complex plots. However, the code effort is higher than if we use e.g. the pandas plot API.\n",
    "The most important plots are shown below, using both Matplotlib and the Pandas API.\n",
    "\n",
    "\n",
    "**Note:** You will find a link to the documentation of each plot in the notebook. If you want to look up how to use it, just follow the link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LQ5cO6Tw_zH"
   },
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQHCnX77Vc8i"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRkvMaOlxEjj"
   },
   "source": [
    "### Correlation Heatmap\n",
    "\n",
    "This plot helps us to get a quick overview and find out which features are correlated with each other.<br>\n",
    "Further information: https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "vCEEmaXfvr-E",
    "outputId": "2fbceff1-4dab-45ce-cff1-86c55c1a2027"
   },
   "outputs": [],
   "source": [
    "corMat = data.corr()\n",
    "sns.heatmap(corMat, xticklabels=corMat.columns, yticklabels=corMat.columns, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lt38aMBxKSH"
   },
   "source": [
    "### Scatterplot\n",
    "\n",
    "Sometimes we just need to plot two single features against each other. In this case we can create a scatterplot.<br>\n",
    "Matplotlib: https://matplotlib.org/3.3.4/api/_as_gen/matplotlib.pyplot.scatter.html <br>\n",
    "Pandas: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "WRpMknkJqp_t",
    "outputId": "d50a712b-6c6b-42a0-8e78-ea4ce2731acf"
   },
   "outputs": [],
   "source": [
    "plt.plot( data['grandTotal'], data['meanPricePerItem'], 'x', color='red' )\n",
    "plt.xlabel('grand total')\n",
    "plt.ylabel('mean price per item')\n",
    "plt.title('grand total vs. mean price per item')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "WLqV5x-SvZ0f",
    "outputId": "d12954a4-855e-4b23-9270-6c256b52d851"
   },
   "outputs": [],
   "source": [
    "data.plot.scatter(x='grandTotal', y='meanPricePerItem');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some relation between meanPricePerItem and grandTotal. How can we explain this plot? Is the information useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGUKAyiVxauj"
   },
   "source": [
    "### Boxplot\n",
    "\n",
    "What is the mean of a feature? How is it distributed? Are there outliers? A simple boxplot can answer all these questions <br>\n",
    "Matplotlib: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html<br>\n",
    "Pandas: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "wivz10CpsHlo",
    "outputId": "05db1abf-2019-4e1c-ea88-c450eb3a62ff"
   },
   "outputs": [],
   "source": [
    "bxdct = plt.boxplot( data['grandTotal'])\n",
    "plt.xlabel('grandTotal')\n",
    "plt.title('Boxplot of grandTotal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "uRGP1X1Lu8e3",
    "outputId": "0c3e860d-ecfe-43eb-8910-fe03e22a0ff3"
   },
   "outputs": [],
   "source": [
    "data['grandTotal'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpsaEmZTxclx"
   },
   "source": [
    "### Histogram\n",
    "\n",
    "Histograms are an easy way to get a first impression of the distribution of a feature. It helps us to find out which values are more common and which ones rarely occur. If some values occur never / more often than others / less than others we should ask ourselfs if there is a reason.\n",
    "\n",
    "Matplotlib: https://matplotlib.org/3.3.4/api/_as_gen/matplotlib.pyplot.hist.html<br>\n",
    "Pandas: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "w52vquG-vimQ",
    "outputId": "0ec7533b-0962-4bc9-ff93-5d0da2093c1e"
   },
   "outputs": [],
   "source": [
    "ax = plt.hist( data['totalScanTimeInSeconds'] , bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "uHYbipy9q4Lp",
    "outputId": "e282b4ba-bdce-44f1-cf50-cedf52f726a3"
   },
   "outputs": [],
   "source": [
    "data['totalScanTimeInSeconds'].hist( bins=20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U47pPCwHu6a_"
   },
   "source": [
    "### Displot\n",
    "\n",
    "Displots are a powerful tool to learn more about feature distribution. We can look at a histogram as well as the density distribution of individual features. The keyword 'hue' can also be used to distinguish between different classes.\n",
    "\n",
    "Documentation:https://seaborn.pydata.org/generated/seaborn.displot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "L1UzjXMzrcLf",
    "outputId": "47fa4115-e18a-469a-bd82-e8cc11a2c5d1"
   },
   "outputs": [],
   "source": [
    "sns.displot(data=data, x=\"trustLevel\", hue=\"fraud\", multiple=\"stack\", kind='hist', kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=data, x=\"meanPricePerItem\", hue=\"fraud\", multiple=\"stack\", kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzwzJ-m2yEg-"
   },
   "source": [
    "### Scatter-Matrix\n",
    "\n",
    "\n",
    "\"One plot to rule them all\". Just like the correlation-heatmap, we can use this plot to get an overview of some features. Note that this plot can get very big if we use many features! It shows provides a scatterplot for each pair of features and a kernel-density-estimation for each individual feature. Like we already saw in the displot, we can distinguish between different classes using the 'hue' keyword.\n",
    "\n",
    "Documentation: https://seaborn.pydata.org/generated/seaborn.pairplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F66ikjV-E3JG"
   },
   "outputs": [],
   "source": [
    "scatterMat_features = ['valuePerSecond','meanPricePerItem','totalScanTimeInSeconds','lineItemVoidsPerPosition','fraud']\n",
    "sns.pairplot(data[scatterMat_features], hue='fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLwDFUkqxugi"
   },
   "source": [
    "### Line Graph\n",
    "\n",
    "If we can look at a feature over a period of time, then a line graph can be helpful.\n",
    "\n",
    "Documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html### Line Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "Au0PzLi0Kvs2",
    "outputId": "18265703-6742-40d4-f6a6-82f3df7a8152"
   },
   "outputs": [],
   "source": [
    "monthlyReport = data.groupby(['checkoutMonth','checkoutYear']).sum()\n",
    "monthlyReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "KMBYJvmFOD8J",
    "outputId": "a3e429d7-dbdb-49b2-8db7-a73027e5389a"
   },
   "outputs": [],
   "source": [
    "monthlyReport.plot(y='fraud', kind = 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXiqeXTRzR5z"
   },
   "source": [
    "### Now you: Plotting\n",
    "1) The manager wants to know the monthly turnover. Create a plot that shows the monthly turnover (sum over grandTotal). Use Panda's plotting API to do this.\n",
    "\n",
    "2) You want to prove that people make more expensive purchases during the Christmas season and therefore the turnover per transaction is higher. Create a suitable plot to test the claim.\n",
    "\n",
    "***Hint***: You need to group the data again, using mean() instead of sum()\n",
    "\n",
    "3) In order to prevent frauds, you want to employ additional personnel. Since this is a costly meassure, you want to limit the working time, to the hours with the highest risk of fraud. Create a plot, that shows, at what time fraudulent transactions take place most frequently.\n",
    "\n",
    "4) You are convinced that some stores make a good job preventing fraud while others don't. Check if you can prove that at some stores (storeLocation) a disproportionate amount of fraud takes place. You could check this hypothesis by investigating the proportion of fraudulent transactions per store.\n",
    "\n",
    "***Hint***: To do so, you can regroup the data by the 'storeLocation' feature. By using the count()-method you will get the total number of transactions per store. The sum()-method will yield the number of fraudulent transactions. Maybe the displot above can provide you some help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMsJOegdZz0c"
   },
   "source": [
    "Solution 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "7WF04rNKWWhf",
    "outputId": "b7488b7d-d481-4e41-e155-c5ef9994ea8c"
   },
   "outputs": [],
   "source": [
    "monthlyReport.plot(y='grandTotal', kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zJkgTRaaCK-"
   },
   "source": [
    "Solution 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "P6C91xjLWWj3",
    "outputId": "90a9b517-3de2-4b73-88a1-d201b774bd17"
   },
   "outputs": [],
   "source": [
    "monthlyReport = data.groupby(['checkoutMonth','checkoutYear']).mean()\n",
    "monthlyReport.plot(y='grandTotal', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNGJp9KMaEo_"
   },
   "source": [
    "Solution 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "cGrqZ1TRRPGD",
    "outputId": "9f80d719-6b92-4b35-da01-80cdb492a284"
   },
   "outputs": [],
   "source": [
    "hourlyReport = data.groupby('checkoutDayTime').sum()\n",
    "hourlyReport.plot(y='fraud', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rp0mgpseXq6"
   },
   "source": [
    "In comparison to the the unfraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "99nlngIgeeur",
    "outputId": "d08ad518-0b48-409c-bb75-a2794e490f60"
   },
   "outputs": [],
   "source": [
    "#hourlyReport = data.groupby(['checkoutDayTime', 'fraud']).size().unstack(level=1)\n",
    "#hourlyReport.plot(kind='bar', stacked=True)\n",
    "sns.displot(data=data, x=\"checkoutDayTime\", hue=\"fraud\", multiple=\"stack\", kind='hist', kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNB-JZXKZrKp"
   },
   "source": [
    "Solution 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "z9MB2HwSXl7w",
    "outputId": "c61c7b7a-dccc-45d7-a66c-ce8b59203d36"
   },
   "outputs": [],
   "source": [
    "localReport = data.groupby('storeLocation').sum()\n",
    "localTransactions = data.groupby('storeLocation').count()\n",
    "localReport.plot(y=['fraud'], kind='bar')\n",
    "localTransactions.plot(y=['fraud'], kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EL6X39l9ZtVm"
   },
   "source": [
    "Solution 4) Using a single plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "TJuMadUNZuzO",
    "outputId": "eb1cdfb7-3e86-4bc2-c293-6e9cfd70f0ca"
   },
   "outputs": [],
   "source": [
    "#localReport = data.groupby(['storeLocation', 'fraud']).size().unstack(level=1)\n",
    "#localReport.plot(kind = 'bar', stacked=True)\n",
    "sns.displot(data=data, x=\"storeLocation\", hue=\"fraud\", multiple=\"stack\", kind='hist', kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKQZO8szUlT6"
   },
   "source": [
    "## 4. Data Preparation\n",
    "Preprocessing & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8jEuiar2_im"
   },
   "source": [
    "### Check dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdwBh8UnVdYj",
    "outputId": "ce78291f-53f6-4d49-aeb3-d206517dc6f5"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iIlz_J43Zi5"
   },
   "source": [
    "### Replace NA-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOH-EHtoaXNJ"
   },
   "source": [
    "NA-Values can cause problems when fitting models. Therefore, we want to fill these gaps in our dataset.\n",
    "There are several options to do so. For example we can either fill a gap with the next valid observation 'bfill' or with the previous valid ovservation 'ffill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3FKcEyXmpBI",
    "outputId": "2b356343-94af-4627-8b3d-57b4167d1566"
   },
   "outputs": [],
   "source": [
    "data['customer_sex'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82-qWdmumseA"
   },
   "outputs": [],
   "source": [
    "data['customer_sex'] = data['customer_sex'].fillna(value='Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-tzCtZC4OMq"
   },
   "source": [
    "### Standardization and Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_8Ya9jl4aHX"
   },
   "source": [
    "#### Normalization: Scale values between 0 and 1\n",
    "Sometimes we want to check if two datapoints are similar to each other. We could do so by comparing the values of each feature for the given datapoints. But what happens if one feature ranges from 0 to 100 and the other from 0.1 to 0.2 ? A difference of 5 in the first feature is not as much as a distance of 0.05 in the second! In order to be able to compare the difference of feature values we should scale them to the same range e.g. between 0 and 1. Then a difference of 0.5 has the same importance - no matter what feature we are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zr_J6O8p4TFq"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data[['valuePerSecondScaled']] = scaler.fit_transform(data[['valuePerSecond']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "-7EpL1ag1Wii",
    "outputId": "94c170a7-8316-41a9-cd24-1c0fa6b1dd02"
   },
   "outputs": [],
   "source": [
    "sns.displot(data['valuePerSecond'], kind='kde')\n",
    "plt.xlim(0,2)\n",
    "plt.title('Unscaled')\n",
    "sns.displot(data['valuePerSecondScaled'], kind='kde')\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,10)\n",
    "plt.title('Normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsbPJ9Xg5-nY"
   },
   "source": [
    "#### Standardization: Scale with mean of 0 and std of 1\n",
    "Sometimes scaling between 0 and 1 isn't enough. What if we do not care about the actual value of a feature but more about its deviation from a certain value e.g. the mean value? In this case it makes sense to scale our feature in a way, so that the values have a mean of 0 and a standard deviation of 1. Therefore we can easily see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abgWvpC06BEP"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data[['scannedLineItemsPerSecondScaled']] = scaler.fit_transform(data[['scannedLineItemsPerSecond']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "id": "GW6RJU2K63UI",
    "outputId": "ed51c674-4bdf-4f97-ac3a-5563e061f767"
   },
   "outputs": [],
   "source": [
    "sns.displot(data['scannedLineItemsPerSecond'], kind='kde')\n",
    "plt.xlim(-2,2)\n",
    "plt.title('Unscaled')\n",
    "sns.displot(data['scannedLineItemsPerSecondScaled'], kind='kde')\n",
    "plt.xlim(-2,2)\n",
    "plt.title('Normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfpEvfWx7yhO"
   },
   "source": [
    "### Dummy Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXhENjxu3gAA"
   },
   "source": [
    "We often have to deal with categorial features. In order to be able to work with them, we often have to encode them correctly. There are two approaches for this task:\n",
    "\n",
    "***One-Hot Encoding***\n",
    "\n",
    "One-hot encoding means converting each category value into a new column and assigns a 1 or 0 (True/False) value to the column\n",
    "\n",
    "We apply One-Hot Encoding when:\n",
    "1. The categorical feature is not ordinal (e.g. a set of countries which is encoded using numbers)\n",
    "2. The number of categorical features is less so one-hot encoding can be effectively applied\n",
    "\n",
    "***Label Encoding***\n",
    "\n",
    "Label encoding is simply converting each value in a column to a number\n",
    "\n",
    "We apply Label Encoding when:\n",
    "1. The categorical feature is ordinal (e.g. trust_level 2 is better than trust level 1)\n",
    "2. The number of categories is quite large as one-hot encoding can lead to high memory consumption \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_74sRdZS3p_6"
   },
   "source": [
    "#### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dy4iSN6kp1sA",
    "outputId": "c8f741fd-c6e2-4c14-d48f-ff80c89bc84a"
   },
   "outputs": [],
   "source": [
    "data['customer_sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "Pvu7i0shqYgf",
    "outputId": "31b65941-9a1c-4446-a2f5-95825e79b613"
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(data['customer_sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RhfMn0_3sDg"
   },
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdC_MfHu3uAc",
    "outputId": "f9486995-aeb8-4480-99c6-425afa77a7ae",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['paymentType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1KItz4gnRMD",
    "outputId": "83b58594-7805-487d-cd5c-9844c6db5141"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data['paymentType'])\n",
    "data['paymentType'] = le.transform(data['paymentType'])\n",
    "data['paymentType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYWFzV9B3wCD"
   },
   "source": [
    "### Now you: Preprocessing\n",
    "1) Encode the feature storeLocation with a suitable encoding Method\n",
    "\n",
    "2) perform a Normalization for the feature grandTotal. Save the calculated feature as grandTotalScaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlloVjHecSFu"
   },
   "outputs": [],
   "source": [
    "# 1)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data['storeLocation'])\n",
    "data['storeLocation'] = le.transform(data['storeLocation'])\n",
    "\n",
    "# 2)\n",
    "scaler = StandardScaler()\n",
    "data[['grandTotal']] = scaler.fit_transform(data[['grandTotal']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL0ZM85lU_bW"
   },
   "source": [
    "# Linkit Grundlagenschulung (2. Teil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ap4ITkVvUlWc"
   },
   "source": [
    "## 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXf1JiWU7I3k"
   },
   "source": [
    "In the first session, we have taken all the necessary steps to load and prepare the data. \n",
    "In the next to chapters, we will learn how we can train a model that is able to classify the transactions into fraudulent and non-fraudulent transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to make sure what our goal is. Here in this case, it will be the detection of fraudulent transactions, therefore we have a classification task at hand. <br>\n",
    "Before we can begin choosing a model, we need to seperate the data into features (X), which are the inputs for the model and the label (y), which the classifier will try to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoMnn1xN7gI3"
   },
   "source": [
    "Let's recap on the types of features we have in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y84c0BxO8E6c",
    "outputId": "a933f452-a1bb-4b61-9302-04a6a336c874"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuKY-cbVieyr"
   },
   "outputs": [],
   "source": [
    "# We can now decide to either take all the features and only drop the column with the label\n",
    "X = data.drop(['fraud'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or explicitly select a subset of features we want to use for the classification  \n",
    "X = data[['trustLevel', 'grandTotal', 'totalScanTimeInSeconds', 'checkoutDayTime']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: There are smarter ways on deciding which features might be relevant for the classification process. For this introductory lesson, we just pick the once that sound the most promising ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we select the column / feature that we want to predict - 'fraud'\n",
    "y = data['fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXyIhqfd82Zc"
   },
   "source": [
    "Now we have the data ready for our classifier -- we have sperated the features (X) from the label (y)\n",
    "\n",
    "Next, we need to decide what classifier we want to use for our prediction\n",
    "\n",
    "The scikit-learn library gives us a nearly endless choice of classifiers we can use. \n",
    "\n",
    "We start with a very simple classifier, the k-nearest neighbor classifier. \n",
    "\n",
    "More Information: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grBNLSMYtDLv",
    "outputId": "f0a94526-605d-4ddc-86d6-f475b35696dd"
   },
   "outputs": [],
   "source": [
    "# We first need to import the selected classifier from scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# The next step is to create an instance of the selected classifier-class\n",
    "clf_nn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already decided in a Hyperparameter for the model. By choosing n_neighbors=5, we tell the model to look for the 5 nearest data points to determine the class of a unknown data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2s3bZgZtDL3",
    "outputId": "2c0a0a28-62e2-4c65-bb0a-455d374ed65c"
   },
   "outputs": [],
   "source": [
    "# Next up, we can call the fit() method, which takes the features X and the label y\n",
    "# to train the selected classifier\n",
    "clf_nn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTHm4RPUtDL4",
    "outputId": "fbfb9ba7-a027-4e22-b5e4-760b6e9569b3"
   },
   "outputs": [],
   "source": [
    "# Now we can easily check with the method score(), how good our classifier is\n",
    "clf_nn.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ei5N758U_sH9"
   },
   "source": [
    "Wow! That score seems to be pretty good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEmcCgsQNhja"
   },
   "source": [
    "### Now you: Modeling\n",
    "Let's see if, using a different method, we can even get a better score! \n",
    "\n",
    "1) Try using a Decision Tree Classifier to predict the fraudulent transactions. \n",
    "\n",
    "(Hint: Look into the API if you get stuck... [Scitkit-learn: DecisionTreeClassifier API](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))\n",
    "\n",
    "2) See what happens if you change the parameter controlling the maximum depth of the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B70xel7oxKz_"
   },
   "source": [
    "Solution 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4JBCQ2GNfR6",
    "outputId": "965c61ab-e63e-49a4-fb81-727c275c195d"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(X, y)\n",
    "clf_dt.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW25i0FuxO_P"
   },
   "source": [
    "Solution 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqkkVTzWyTdt",
    "outputId": "29c767af-322e-4a64-8f4a-30c28e29fa4e"
   },
   "outputs": [],
   "source": [
    "clf_dt_1 = DecisionTreeClassifier(max_depth=1)\n",
    "clf_dt_1.fit(X, y)\n",
    "clf_dt_1.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtTpdcNpxbUa",
    "outputId": "b96f846f-e862-4aff-b967-bda4f077bd15"
   },
   "outputs": [],
   "source": [
    "clf_dt_2 = DecisionTreeClassifier(max_depth=2)\n",
    "clf_dt_2.fit(X, y)\n",
    "clf_dt_2.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tMOYFG4x5OB",
    "outputId": "c6a29b1f-9d89-4fc4-8515-844e3706a407"
   },
   "outputs": [],
   "source": [
    "clf_dt_3 = DecisionTreeClassifier(max_depth=5)\n",
    "clf_dt_3.fit(X, y)\n",
    "clf_dt_3.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we might have done something wrong.. \n",
    "\n",
    "the results of our very simple classifiers seem too good to be true.\n",
    "\n",
    "But what problem are we facing here exactly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-51nNVF_UlY6"
   },
   "source": [
    "## 6.  Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "io1sr7A2CMoy"
   },
   "source": [
    "As we want our model to perform good on unseen data (and not on the training data) we now split our dataset in 2 pieces: a trainset and a testset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWJJoxWtAEmK"
   },
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tinLip_1jM55"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12LqtQUAjQg6"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQU4h6VsGLqF"
   },
   "source": [
    "Lets train our decision tree again, but now only on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCzAska_Oue9",
    "outputId": "49c984b5-8e42-4e45-d0e4-9abbad8904e5"
   },
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_dt.fit(X_train, y_train)\n",
    "# clf_dt.score(X_train, y_train)\n",
    "clf_dt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yolcP5imLwur"
   },
   "source": [
    "Still pretty good isn't it? Maybe too good? Let's find it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_tree(clf_dt, feature_names=X_train.columns, class_names=['non-fraud', 'fraud'], max_depth=3, proportion=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first three nodes of the decision tree already seperate the data pretty well. Maybe we can reduce the maximum depth of the tree to prevent it from overfitting?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(max_depth=3)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "# clf_dt.score(X_train, y_train)\n",
    "clf_dt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! This really worked out. With a decreased depth of 3 our model now actually performs better on the unseen test data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does the score() method really tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r6-LUAxALL3"
   },
   "source": [
    "### Overview over different Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXdscge0DI2x"
   },
   "source": [
    "To evaluate the performance of our model, we have to determine a quantified comparision of the predicition and the ground truth. There are plenty of options for quantification, lets get a quick overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhBqWVWMDECO"
   },
   "outputs": [],
   "source": [
    "y_pred = clf_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFjX_1B-faXR",
    "outputId": "0c0d52a0-32bc-4d33-9647-f785d20e9cb3"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy: %8.5f\" % accuracy)\n",
    "print(\"Precision: %8.5f\" % precision)\n",
    "print(\"Recall: %8.5f\" % recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h40UUL8C8c_z"
   },
   "source": [
    "Learn more about how the metrics work in detail in the [documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).\n",
    "\n",
    "To learn more about how to print properly formated numbers click [here](https://www.geeksforgeeks.org/python-output-formatting/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "730pBH-NAQRf"
   },
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oY2rs2VmPeg"
   },
   "source": [
    "Now we have a quantified evaluation of our model. But how can we determine if this score should be considered good or bad?\n",
    "\n",
    "Lets compare it to a dummy classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6LxG1RQlpig",
    "outputId": "53a78ac9-4b9b-4932-ed09-8fb8e15fb82e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
    "dummy_clf.fit(X, y)\n",
    "y_pred = dummy_clf.predict(y_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of a dummy classifier: %8.5f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvSpdYuOMC5p"
   },
   "source": [
    "If we just guess randomly, we still reach an accuracy of about 50%. We should keep that in mind, when evaluating our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5Ka7F1nz7Ni"
   },
   "source": [
    "### Now you: Evaluation\n",
    "Test your model (Decision Tree) using a Train-Test-Split. Choose three different metrics for evaluation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = X.copy()\n",
    "my_labels = y.copy()\n",
    "random.seed(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkXdX0l-0dSh",
    "outputId": "b0d402e4-c8cf-4990-a53b-222b22359c9c"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(my_data, my_labels, test_size=0.2, shuffle=True)\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(max_depth=2)\n",
    "clf_dt.fit(train_data, train_labels)\n",
    "y_pred = clf_dt.predict(test_data)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, test_labels)\n",
    "print(\"Accuracy: %4.2f\" % accuracy)\n",
    "precision = metrics.precision_score(y_pred, test_labels)\n",
    "print(\"Precision: %4.2f\" % precision)\n",
    "recall = metrics.recall_score(y_pred, test_labels)\n",
    "print(\"Recall: %4.2f\" % recall)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wAOouqFoW_-Y",
    "xjVVod5nsY_g",
    "9LQ5cO6Tw_zH",
    "yRkvMaOlxEjj",
    "-lt38aMBxKSH",
    "VGUKAyiVxauj",
    "SpsaEmZTxclx",
    "U47pPCwHu6a_",
    "vzwzJ-m2yEg-",
    "RLwDFUkqxugi",
    "oKQZO8szUlT6",
    "e8jEuiar2_im",
    "4iIlz_J43Zi5",
    "A-tzCtZC4OMq",
    "4_8Ya9jl4aHX",
    "MsbPJ9Xg5-nY",
    "kfpEvfWx7yhO",
    "_74sRdZS3p_6",
    "7RhfMn0_3sDg",
    "QYWFzV9B3wCD",
    "CO2Czo8uU4oN",
    "ZL0ZM85lU_bW",
    "Ap4ITkVvUlWc",
    "KEmcCgsQNhja",
    "-51nNVF_UlY6",
    "OWJJoxWtAEmK",
    "5r6-LUAxALL3",
    "730pBH-NAQRf",
    "nQdXn0GZrS-b",
    "L5Ka7F1nz7Ni"
   ],
   "name": "Linkit-Grundlagenschulung.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}